---
layout: post
title: Literature Review Introduction
date: 2014-12-05 16:27:31
disqus: y
---

Over the next few weeks, I will be posting a 4-part series of blog posts that will together serve as the literature review for this project. This literature review will describe the current state of evaluation "science", so to speak, and identify gaps in the body of literature that our research project seeks to fill. I'll be breaking it into manageable pieces in the form of blog posts, so it will be easier to follow than a standard literature review in its entirety.   

The blog posts will be organized as follows: after this introduction, I will introduce and describe volunteer & technical communities \(V&TCs\) in more depth. I'll then draw out the broadest contours of evaluation research, and identify the places for our evaluation framework. Next I imagine a real-time impact evaluation framework for the V&TCs, in order for the formal humanitarian sector to measure and communicate the impacts of collaborating with V&TCs. I will end by posing some pressing research questions raised by this literature review.   

With that, here is the Introduction to our review.  


The past decade has seen the proliferation of two distinct phenomena. The first is a widespread interest in frameworks for evaluating humanitarian actions. Such evaluations measure the impacts of humanitarian operations, with the goal of improving future work in the area. Evaluations range in purpose, scope, and tactics, from real-time evaluations, to joint agency evaluations, to utilization-focused evaluations; however, they all aim to generate knowledge about the practices within a particular humanitarian intervention.   

The second phenomenon has been the development of volunteer & technical communities (V&TCs) that emerge to assist in the collection, processing, and representation of humanitarian data. These communities are typically comprised of volunteers distributed across the world who collaborate with humanitarian institutions through digital technologies such as Skype and Ushahidi. The Standby Task Force and the Digital Humanitarian Network are examples of V&TCs, and these communities are mobilized at a humanitarian agencyâ€™s request to collect, process, collate, and represent data in humanitarian crises. Such tasks include, for instance, processing aerial photography, creating digital outlines of infrastructure, and geolocating SMS messages sent to reserved emergency numbers.   

Recent attention has focused on how to productively bring together these two developments. V&TCs are interested in articulating their perceived contribution to humanitarian practices, while facing such broad challenges as slow technological adoption and institutional and policy barriers. Meanwhile, humanitarian organizations hope V&TCs may increase the efficiency and speed of humanitarianism. To date, V&TCs have been activated in a number of humanitarian contexts, but outcomes and lessons learned from these projects remain primarily in the realm of anecdotes and unsystematic recollections. Few have successfully developed methodical approaches to evaluating humanitarian collaborations with V&TCs. Indeed, both V&TCs and humanitarian agencies have expressed the desire to establish community-wide evaluation frameworks, in order to systematize measuring the impact of these collaborations.   

In this paper I work toward this goal by surveying existing research on evaluation frameworks, and making preliminary observations on where a V&TC evaluation framework could be situated. By mapping the landscape of evaluation literature, I will draw out the metrics, principles, and approaches that might guide an evaluation framework for V&TCs. That is, in this paper I do not evaluate any particular V&TC activation; instead I review the diverse evaluation frameworks that researchers have developed to assist humanitarian organizations.   

The rest of this paper is structured as follows: I first introduce V&TCs in greater depth, suggesting that evaluation frameworks are imperatively needed by these communities. I then provide a literature review of evaluation frameworks research. In doing so, I identify common principles and guidelines drawing from two related focus areas: impact evaluations, which aim to measure the overall success or failure of a project; and real-time evaluations, which seek to evaluate humanitarian interventions more broadly than mere impact, doing so in real-time to accelerate the improvement of projects as they unfold.  After this review I envision a real-time impact evaluation framework, laying out the broad terms and principles one such framework might borrow. Lastly, I elucidate a number of pressing research challenges raised by this proposal, looking toward refinement and future improvements.   